{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms\n",
    "==========\n",
    "In scientific python, histograms seem to be considered as a plot style, on equal footing with, e.g. scatter plots.\n",
    "It may well be that HEP is the only place where users need to plot *pre-binned* data, and thus must use histograms as persistent objects representing reduced data.  This notebook will discuss a few ways that such objects can be manipulated.\n",
    "\n",
    "A histogram object roughly goes through three stages in its life:\n",
    "   - Filling\n",
    "   - Transformation (projection, rebinning, integrating)\n",
    "   - Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling\n",
    "Let's start with filling.  We'll use a random distribution [near and dear](https://en.wikipedia.org/wiki/ARGUS_distribution) to of b and c factory physicists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import argus\n",
    "\n",
    "vals = argus(chi=.5).rvs(size=1000)\n",
    "\n",
    "hist = np.histogram(vals)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're done, right?\n",
    "Probably not: we have more than 1000 events, and probably need to use some map-reduce paradigm to fill the histogram because we can't keep all 1 billion `vals` in memory.  So we need two things: a binning, so that all histograms that were independently created can be added, and the ability to add two histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning = np.linspace(0, 1, 50)\n",
    "\n",
    "def add_histos(h1, h2):\n",
    "    h1sumw, h1binning = h1\n",
    "    h2sumw, h2binning = h2\n",
    "    if h1binning.shape == h2binning.shape and np.all(h1binning==h2binning):\n",
    "        return h1sumw+h2sumw, h1binning\n",
    "    else:\n",
    "        raise ValueError(\"The histograms have inconsistent binning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals2 = argus(chi=.5).rvs(size=1000)\n",
    "\n",
    "hist1 = np.histogram(vals, bins=binning)\n",
    "hist2 = np.histogram(vals, bins=binning)\n",
    "\n",
    "hist = add_histos(hist1, hist2)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have everything we need to make our own TH1, from a filling perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myTH1:\n",
    "    def __init__(self, binning):\n",
    "        self._binning = binning\n",
    "        self._sumw = np.zeros(binning.size - 1)\n",
    "    \n",
    "    def fill(self, values, weights=None):\n",
    "        sumw, _ = np.histogram(values, bins=self._binning, weights=weights)\n",
    "        self._sumw += sumw\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, myTH1):\n",
    "            raise ValueError\n",
    "        if not np.array_equal(other._binning, self._binning):\n",
    "            raise ValueError(\"The histograms have inconsistent binning\")\n",
    "        out = myTH1(self._binning)\n",
    "        out._sumw = self._sumw + other._sumw\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning = np.linspace(0, 1, 50)\n",
    "\n",
    "h1 = myTH1(binning)\n",
    "h1.fill(vals)\n",
    "\n",
    "h2 = myTH1(binning)\n",
    "h2.fill(vals2)\n",
    "\n",
    "h = h1 + h2\n",
    "print(h._sumw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework: add `sumw2` support.\n",
    "\n",
    "Of course, we might want multidimensional histograms.  There is `np.histogramdd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = np.random.multivariate_normal(mean=[1, 3, 7], cov=np.eye(3), size=10000)\n",
    "\n",
    "xbins = np.linspace(-10, 10, 20)\n",
    "ybins = np.linspace(-10, 10, 20)\n",
    "zbins = np.linspace(-10, 10, 20)\n",
    "hnumpy = np.histogramdd(xyz, bins=(xbins, ybins, zbins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but we are becoming challenged by book-keeping of the variables.\n",
    "The histogram utility in Coffea is designed to simplify this operation, and the eventual successor (for filling purposes) [boost-histogram](https://github.com/scikit-hep/boost-histogram#usage) has similar syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coffea.hist as hist\n",
    "\n",
    "hfcat = hist.Hist(\"Counts\",\n",
    "                  hist.Cat(\"sample\", \"sample name\"),\n",
    "                  hist.Bin(\"x\", \"x value\", 20, -10, 10),\n",
    "                  hist.Bin(\"y\", \"y value\", 20, -10, 10),\n",
    "                  hist.Bin(\"z\", \"z value\", 20, -10, 10),\n",
    "                 )\n",
    "\n",
    "hfcat.fill(sample=\"sample 1\", x=xyz[:,0], y=xyz[:,1], z=xyz[:,2])\n",
    "\n",
    "# suppose we have another sample of xyz values\n",
    "xyz_sample2 = np.random.multivariate_normal(mean=[1, 3, 7], cov=np.eye(3), size=10000)\n",
    "\n",
    "# additionally, lets assume entries in sample 2 have weight equal to atan(distance from origin)\n",
    "weight = np.arctan(np.sqrt(np.power(xyz_sample2, 2).sum(axis=1)))\n",
    "\n",
    "# weight is a reserved keyword in Hist\n",
    "hfcat.fill(sample=\"sample 2\", x=xyz_sample2[:,0], y=xyz_sample2[:,1], z=xyz_sample2[:,2], weight=weight)\n",
    "\n",
    "print(hfcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more details, look at:\n",
    "# help(hist.Hist)\n",
    "# help(hist.Bin)\n",
    "# help(hist.Cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few examples of transformations on multidimensional histograms in Coffea.  For each, the docstring (`help(function)` or shift+tab in Jupyter) provides useful info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum all x bins within nominal range (-10, 10)\n",
    "hfcat.sum(\"x\", overflow='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some analog to fancy array slicing for histogram objects, which is supported (with reasonable consistency) in Coffea, where the slice boundaries are physical axis values, rather than bin indices.  All values outside the slice range are merged into overflow bins.\n",
    "\n",
    "For a lengthy discussion on possible slicing syntax for the future, see [boost-histogram#35](https://github.com/scikit-hep/boost-histogram/issues/35)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced = hfcat[:,0:,4:,0:]\n",
    "display(sliced)\n",
    "display(sliced.identifiers(\"y\", overflow='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrate y bins from -2 to +10\n",
    "hfcat.project(\"y\", slice(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebin z axis by providing a new axis definition\n",
    "hfcat.rebin(\"z\", hist.Bin(\"znew\", \"rebinned z value\", [-10, -6, 6, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge categorical axes\n",
    "mapping = {\n",
    "    'all samples': ['sample 1', 'sample 2'],\n",
    "    'just sample 1': ['sample 1'],\n",
    "}\n",
    "hfcat.group(hist.Cat(\"cat\", \"new category\"), \"sample\", mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale entire histogram by 3 (in-place)\n",
    "hfcat.scale(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale samples by different values\n",
    "scales = {\n",
    "    'sample 1': 1.2,\n",
    "    'sample 2': 0.2,\n",
    "}\n",
    "hfcat.scale(scales, axis='sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful debugging tool: print bins, aka 'identifiers'\n",
    "display(hfcat.identifiers('sample'))\n",
    "display(hfcat.identifiers('x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin contents are accessed using values\n",
    "hfcat.sum('x', 'y').values(sumw2=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data can be exported to ROOT via uproot, but only 1D (and soon 2D)\n",
    "import uproot\n",
    "outputfile = uproot.create(\"output.root\")\n",
    "h = hfcat.sum('x', 'y')\n",
    "for sample in h.identifiers('sample'):\n",
    "    outputfile[sample.name] = hist.export1d(h.project('sample', sample))\n",
    "outputfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "The most integrated plotting utility in the scientific python ecosystem, by far, is [matplotlib](https://matplotlib.org/).  However, as we will see, it is not tailored to HEP needs.  To facilitate the transition, there is a developing package called [mpl-hep](https://github.com/nsmith-/mpl-hep#mpl-hep).  Meanwhile, Coffea tools provide several convenience functions to aid in plotting `Hist` objects.\n",
    "\n",
    "Let's start by looking at basic mpl histogramming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter display backends for matplotlib: nbagg, inline, etc.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = argus(chi=.5).rvs(size=1000)\n",
    "\n",
    "# notice the semicolon, which prevents display of the return values\n",
    "plt.hist(vals);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to plot pre-binned data, for example from our earlier `np.histogram` usage.  Here we start running into the edge of typical mpl usage.  As mentioned before, apparently HEP is the only regular user of pre-binned histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning = np.linspace(0, 1, 50)\n",
    "\n",
    "h1vals, h1bins = np.histogram(vals, bins=binning)\n",
    "plt.step(x=h1bins[:-1], y=h1vals, where='post');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coffea utilities include a plotting package to aid in displaying pre-binned histograms.  Here are a small set of example plots that can be made using this utility.  More examples can be found in [this notebook](https://github.com/CoffeaTeam/fnal-column-analysis-tools/blob/master/binder/plotting-demo.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.plot1d(hfcat.sum(\"x\", \"y\"), overlay='sample');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.plot1d(hfcat.sum(\"x\", \"y\"), overlay='sample', stack=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.plot2d(hfcat.sum('x', 'sample'), xaxis='y');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make coarse binned hist and look at several distributions\n",
    "hnew = (hfcat.rebin(\"y\", hist.Bin(\"ynew\", \"rebinned y value\", [0, 3, 5]))\n",
    "        .rebin(\"z\", hist.Bin(\"znew\", \"rebinned z value\", [5, 8, 10]))\n",
    "       )\n",
    "\n",
    "hist.plotgrid(hnew, row='ynew', col='znew', overlay='sample');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = hfcat.project('sample', 'sample 1').sum('y', 'z')\n",
    "denominator = hfcat.sum('sample', 'y', 'z')\n",
    "\n",
    "numerator.title = r'$\\epsilon$'\n",
    "fig, ax, _ = hist.plotratio(num=numerator,\n",
    "                            denom=denominator,\n",
    "                            error_opts={'color': 'k', 'marker': '.'},\n",
    "                            unc='clopper-pearson'\n",
    "                           )\n",
    "ax.set_ylim(0.6, 1.)\n",
    "ax.set_xlim(-10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
