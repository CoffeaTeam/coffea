global coffea_udf


@fn.pandas_udf(BinaryType(), fn.PandasUDFType.SCALAR)
def coffea_udf(dataset, {% for col in cols %}{{col}}{{ "," if not loop.last }}{% endfor %}):
    global processor_instance, lz4_clevel
    
    columns = [{% for col in cols %}{{col}}{{ "," if not loop.last }}{% endfor %}]
    names = [{% for col in cols %}{{"'"|safe+col+"'"|safe}}{{ "," if not loop.last }}{% endfor %}]

    size = dataset.size
    items = {}

    offsets_store = {}

    for i, col in enumerate(columns):
        # numpy array
        if columns[i].array[0].base is None:
            items[names[i]] = columns[i].values
        else:
            prefix = names[i].split('_')[0] # this is specific to nanoaod, sadness            
            if prefix not in offsets_store.keys():
                counts = columns[i].str.len().values
                offsets_store[prefix] = np.zeros(shape=(counts.size + 1, ), dtype=np.int64)
                offsets_store[prefix][1:] = np.cumsum(counts)
            offsets = offsets_store[prefix]
            contents = np.squeeze(columns[i].array[0].base)
            items[names[i]] = awkward.JaggedArray.fromoffsets(offsets, contents)

    df = processor.PreloadedDataFrame(size=size, items=items)
    df['dataset'] = dataset[0]
    
    vals = processor_instance.process(df)
    
    valsblob = lz4f.compress(pkl.dumps(vals), compression_level=lz4_clevel)
    
    outs = np.full(shape=(size, ), fill_value=b'', dtype='O')
    outs[0] = valsblob
    
    return pd.Series(outs)


@fn.pandas_udf(BinaryType(), fn.PandasUDFType.SCALAR)
def coffea_udf_flat(dataset, {% for col in cols %}{{col}}{{ "," if not loop.last }}{% endfor %}):
    global processor_instance, lz4_clevel
    
    columns = [{% for col in cols %}{{col}}{{ "," if not loop.last }}{% endfor %}]
    names = [{% for col in cols %}{{"'"|safe+col+"'"|safe}}{{ "," if not loop.last }}{% endfor %}]

    size = dataset.size
    items = {}

    for i, col in enumerate(columns):
        # numpy array
        if columns[i].array[0].base is None:
            items[names[i]] = columns[i].values
        else:
            items[names[i]] = np.squeeze(columns[i].array[0].base)

    df = processor.PreloadedDataFrame(size=size, items=items)
    df['dataset'] = dataset[0]
    
    vals = processor_instance.process(df)
    
    valsblob = lz4f.compress(pkl.dumps(vals), compression_level=lz4_clevel)
    
    outs = np.full(shape=(size, ), fill_value=b'', dtype='O')
    outs[0] = valsblob
    
    return pd.Series(outs)
